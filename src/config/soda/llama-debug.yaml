# @package _global_

defaults:
  - llama-7b

data:
  max_eval_samples: 10

training:
  per_device_train_batch_size: 1

  learning_rate: 3.0e-4
  lr_scheduler_type: constant

  logging_steps: 1
  eval_steps: 2
  save_steps: 2
  max_steps: 2

wandb:
  name: debug
  log: false