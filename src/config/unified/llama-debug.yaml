# @package _global_

defaults:
  - llama-7b

data:
  max_eval_samples: 10

training:
  learning_rate: 3.0e-4
  lr_scheduler_type: constant

  peft: true
  peft_type: lora
  lora_r: 8
  target_modules: q_proj,k_proj,v_proj,o_proj

  logging_steps: 1
  eval_steps: 10
  save_steps: 10
  max_steps: 10

wandb:
  name: debug
  log: false